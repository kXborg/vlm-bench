{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cae7aa-2c20-423b-a59e-840fac4a34f5",
   "metadata": {},
   "source": [
    "## SmolVLM 256M Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abadb6a-b48d-43b5-a345-557a47d7f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304036f7-c5fd-4e1e-af6a-01dc6f58cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load images\n",
    "image = Image.open(\"../tasks/bird.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1011f4-9c82-4277-9d16-0db1d355d9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497fea4c3c09434881108372235124de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opencv/kukil/vlm/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2242: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# Initialize processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-256M-Instruct\")\n",
    "\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-256M-Instruct\",\n",
    "    dtype=torch.bfloat16,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50aee293-132a-4ff5-836a-8e9ec96a98c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprit\u001b[49m(model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prit' is not defined"
     ]
    }
   ],
   "source": [
    "prit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27db1662-6095-4840-951f-e26ca52f8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input messages\n",
    "query = \"Can you describe the image?\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": query}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "inputs = inputs.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb03fa9-0a71-4846-99bc-d0c686ca91b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "\n",
      "\n",
      "Can you describe the image?\n",
      "Assistant: The image features a hummingbird in flight. The hummingbird is in the foreground and is flying towards the right side of the image. It has a long, thin beak and is colored in a mix of green and blue. The hummingbird's wings are spread out, and its tail is visible, indicating it is flying. The background of the image is blurred, focusing the viewer's attention on the hummingbird. The background color is a gradient of light green to yellow, which is a common color used in nature to create a sense of depth and movement. The overall composition of the image is balanced, with the hummingbird in the foreground and the background being slightly blurred, creating a sense of depth.\n",
      "\n",
      " Generation Time: 15.67s\n"
     ]
    }
   ],
   "source": [
    "# Generate outputs\n",
    "t1 = time.time()\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "t2= time.time()\n",
    "print(generated_texts[0])\n",
    "print(f\"\\n Generation Time: {round(t2-t1, 2)}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "vlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

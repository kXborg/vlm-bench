{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7740a8c-3917-44ff-bb53-c72d2b050570",
   "metadata": {},
   "source": [
    "## InternVL3.5 - 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91370b5e-0770-484a-83ae-2c7d79db752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention2 is not installed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer, GenerationConfig\n",
    "\n",
    "# Prepare generation config\n",
    "gen_config = GenerationConfig(\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Load tokenizer (needed for chat)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"OpenGVLab/InternVL3_5-1B\", trust_remote_code=True)\n",
    "\n",
    "# Load model with FP16 and low CPU memory usage\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"OpenGVLab/InternVL3_5-2B\",\n",
    "    dtype=torch.float16,    # FP16 for Jetson GPU\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True, \n",
    "    device_map=\"auto\"\n",
    ").eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357e9f86-0d00-4812-85e0-344edc167bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2f651e-b782-4ae8-b171-2a66be003e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Example: load a PIL image\n",
    "img = Image.open(\"../tasks/bird.jpg\").convert(\"RGB\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),   # match model expectation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "img_tensor = preprocess(img).unsqueeze(0).half().to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6d9bf-049e-4a6a-bdbb-0baaa2849a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "question = \"Describe this image\"\n",
    "\n",
    "# Inference with no_grad (saves memory, disables gradient tracking)\n",
    "with torch.no_grad():\n",
    "    output = model.chat(\n",
    "        tokenizer=tokenizer,\n",
    "        pixel_values=img_tensor,\n",
    "        question=question,\n",
    "        generation_config=gen_config.to_dict(),\n",
    "        history=None\n",
    "    )\n",
    "\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "vlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

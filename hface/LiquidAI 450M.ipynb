{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9ae95b-9c10-48cc-8a75-35b366ace6ea",
   "metadata": {},
   "source": [
    "## Liquid AI 450M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53e44f3-7740-41a3-b72a-a60db7e1f6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaf6334de0e4938a27c22e45cb2105f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbe69e673d14a5e93e779a9351a43ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_lfm2_vl.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/LiquidAI/LFM2-VL-450M:\n",
      "- modeling_lfm2_vl.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11636471bcaf436885e3d124e2ae8216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/902M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-09-09T09:43:22.625434Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mReqwest(reqwest::Error { kind: Request, url: \"https://cas-server.xethub.hf.co/reconstruction/e8ddc2abe7f9c5497c6af4a57df332ad878fdfd5ce8f782bccf3273e51ee13b3\", source: hyper_util::client::legacy::Error(SendRequest, hyper::Error(Io, Os { code: 110, kind: TimedOut, message: \"Connection timed out\" })) }). Retrying...\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:226\n",
      "\n",
      "  \u001b[2m2025-09-09T09:43:22.625573Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 738.247526ms before the next attempt\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b966213f0f5449e3acade09298425ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca44dfe39354b28bb6e5ba6a45a632f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/436 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e8d129997f4e8f81c8af920e7a1d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/434 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9a70fd8fdf46f7b9358e06f1b016e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing_lfm2_vl.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/LiquidAI/LFM2-VL-450M:\n",
      "- processing_lfm2_vl.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81623e9fdfd42b6b72d0428fc091b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b8f1c152804907b55ad85383f5220a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/535 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2917cc96a4447b8a2ed3ca5b4bc29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a542b41095451bbed1aa0798fa6757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad40d0fbc684ad5962d54ac4c1433e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/584 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "# Load model and processor\n",
    "model_id = \"LiquidAI/LFM2-VL-450M\"\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    dtype=\"bfloat16\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f214d7-ce68-466a-9c1e-74fe9a64db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "What do you see in the image? Answer in 100 words.\n",
      "assistant\n",
      "The image captures a stunning moment of a hummingbird in mid-flight, hovering near a vibrant flower. The hummingbird's wings are fully extended, showcasing its incredible agility and speed. Its body is a mix of gray and brown feathers, with a distinctive white stripe running down its back. The bird's beak is long and slender, perfectly adapted for feeding on nectar from flowers.\n",
      "\n",
      "The flower, likely a type of lily, has long, slender petals that are a striking orange color. The flower's stem is green, and the petals appear to be slightly drooping, possibly due to the hummingbird\n",
      "\n",
      " Generation Time : 8.53 s\n"
     ]
    }
   ],
   "source": [
    "# Load image and create conversation\n",
    "image = Image.open(\"../tasks/bird.jpg\")\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": \"What do you see in the image? Answer in 100 words.\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Generate Answer\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversation,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    "    tokenize=True,\n",
    ").to(model.device)\n",
    "\n",
    "t1 = time.time()\n",
    "outputs = model.generate(**inputs, max_new_tokens=128)\n",
    "t2 = time.time()\n",
    "\n",
    "gen = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(gen)\n",
    "\n",
    "print(f\"\\n Generation Time : {round(t2-t1, 2)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17cb2567-c6f1-4b62-8e67-1d25a32ad3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "Find the bird and answer it's bbox center coordinate in (x,y) format normalized using image height and width\n",
      "assistant\n",
      "The bird in the image is a hummingbird. Its coordinates in the normalized format are:\n",
      "\n",
      "(0.0, 0.0)\n",
      "\n",
      "This represents the bird's position in the image, with the x-coordinate being 0.0 and the y-coordinate being 0.0.\n",
      "\n",
      " Generation Time : 4.31 s\n"
     ]
    }
   ],
   "source": [
    "# Load image and create conversation\n",
    "image = Image.open(\"../tasks/bird.jpg\")\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": \"Find the bird and answer it's bbox center coordinate in (x,y) format normalized using image height and width\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Generate Answer\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversation,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    "    tokenize=True,\n",
    ").to(model.device)\n",
    "\n",
    "t1 = time.time()\n",
    "outputs = model.generate(**inputs, max_new_tokens=128)\n",
    "t2 = time.time()\n",
    "\n",
    "gen = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(gen)\n",
    "\n",
    "print(f\"\\n Generation Time : {round(t2-t1, 2)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c735f-695f-48bb-ad81-fd09581e69bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "vlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

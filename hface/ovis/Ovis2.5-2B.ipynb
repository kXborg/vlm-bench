{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41628981-61e7-4aac-9faa-1def17c1fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9abe1-32d5-4d6a-9155-8d296f48560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7677f678-6729-4539-b323-7eb052cc1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fe899f0-d216-4e15-a7c2-4c78daf221b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3df3e7730f64323870f9f3ebbc77a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd38f903014f45b289369dd1a3367b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_PATH = \"AIDC-AI/Ovis2.5-2B\"\n",
    "\n",
    "# Thinking mode & budget\n",
    "enable_thinking = False\n",
    "enable_thinking_budget = False  # Only effective if enable_thinking is True.\n",
    "\n",
    "# Total tokens for thinking + answer. Ensure: max_new_tokens > thinking_budget + 25\n",
    "max_new_tokens = 3072\n",
    "thinking_budget = 2048\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "112059d1-5661-4184-a7e4-b9c18b5a576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 542C-8606\n",
      "\n",
      " Directory of C:\\Users\\User\\Desktop\\OpenCV University\\vlm-bench\\hface\\ovis\n",
      "\n",
      "16-09-2025  18:07    <DIR>          .\n",
      "16-09-2025  17:40    <DIR>          ..\n",
      "16-09-2025  17:41    <DIR>          .ipynb_checkpoints\n",
      "09-09-2025  16:02            88,258 bird.jpg\n",
      "16-09-2025  18:07            16,307 Ovis2.5-2B.ipynb\n",
      "               2 File(s)        104,565 bytes\n",
      "               3 Dir(s)  170,820,112,384 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a84355d2-5756-4ead-a0b3-1478d5980dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'bird.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aff945f-e32a-407e-b079-f2c559e69cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hummingbird hovers near a vibrant flower, feeding on nectar. The bird's iridescent green feathers and long beak are visible as it hovers. The flower features bright orange and yellow petals, with some petals appearing dried. The background is softly blurred, creating a warm, yellowish hue that highlights the bird and flower. Another similar flower is partially visible on the left.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"image\", \"image\": Image.open(img)},\n",
    "        {\"type\": \"text\", \"text\": \"Describe the image in 100 words\"},\n",
    "    ],\n",
    "}]\n",
    "\n",
    "input_ids, pixel_values, grid_thws = model.preprocess_inputs(\n",
    "    messages=messages,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=enable_thinking\n",
    ")\n",
    "input_ids = input_ids.cuda()\n",
    "pixel_values = pixel_values.cuda() if pixel_values is not None else None\n",
    "grid_thws = grid_thws.cuda() if grid_thws is not None else None\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs=input_ids,\n",
    "    pixel_values=pixel_values,\n",
    "    grid_thws=grid_thws,\n",
    "    enable_thinking=enable_thinking,\n",
    "    enable_thinking_budget=enable_thinking_budget,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    thinking_budget=thinking_budget,\n",
    ")\n",
    "\n",
    "response = model.text_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d91369-bdc1-47ed-810d-0d3bea0602f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "vlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

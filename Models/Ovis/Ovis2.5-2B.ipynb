{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41628981-61e7-4aac-9faa-1def17c1fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9abe1-32d5-4d6a-9155-8d296f48560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7677f678-6729-4539-b323-7eb052cc1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe899f0-d216-4e15-a7c2-4c78daf221b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8231459ef30f429a9bf1e86b1a609440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_PATH = \"AIDC-AI/Ovis2.5-2B\"\n",
    "\n",
    "# Thinking mode & budget\n",
    "enable_thinking = False\n",
    "enable_thinking_budget = False\n",
    "\n",
    "max_new_tokens = 3072\n",
    "thinking_budget = 2048\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112059d1-5661-4184-a7e4-b9c18b5a576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird.jpg  Ovis2.5-2B.ipynb\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84355d2-5756-4ead-a0b3-1478d5980dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'bird.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aff945f-e32a-407e-b079-f2c559e69cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hummingbird hovers near a vibrant flower, feeding on nectar. The bird's iridescent green feathers and long beak are prominent. The flower features bright orange and yellow petals, with some dried white ones at the bottom. The background is softly blurred, creating a warm, yellowish hue that highlights the subjects. Another similar flower is partially visible on the left.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"image\", \"image\": Image.open('bird.jpg')},\n",
    "        {\"type\": \"text\", \"text\": \"Describe the image in 100 words\"},\n",
    "    ],\n",
    "}]\n",
    "\n",
    "input_ids, pixel_values, grid_thws = model.preprocess_inputs(\n",
    "    messages=messages,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=enable_thinking\n",
    ")\n",
    "input_ids = input_ids.cuda()\n",
    "pixel_values = pixel_values.cuda() if pixel_values is not None else None\n",
    "grid_thws = grid_thws.cuda() if grid_thws is not None else None\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs=input_ids,\n",
    "    pixel_values=pixel_values,\n",
    "    grid_thws=grid_thws,\n",
    "    enable_thinking=enable_thinking,\n",
    "    enable_thinking_budget=enable_thinking_budget,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    thinking_budget=thinking_budget,\n",
    ")\n",
    "\n",
    "response = model.text_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d91369-bdc1-47ed-810d-0d3bea0602f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 18 17:08:09 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti     Off | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   27C    P8               5W / 350W |      3MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63313b20-7f27-49a7-8343-180464ff1636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"return_dict\": true,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_attentions\": false,\n",
      "  \"torchscript\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"use_bfloat16\": false,\n",
      "  \"tf_legacy_loss\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"chunk_size_feed_forward\": 0,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"is_decoder\": false,\n",
      "  \"cross_attention_hidden_size\": null,\n",
      "  \"add_cross_attention\": false,\n",
      "  \"tie_encoder_decoder\": false,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_beam_groups\": 1,\n",
      "  \"diversity_penalty\": 0.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"typical_p\": 1.0,\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"encoder_no_repeat_ngram_size\": 0,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_scores\": false,\n",
      "  \"return_dict_in_generate\": false,\n",
      "  \"forced_bos_token_id\": null,\n",
      "  \"forced_eos_token_id\": null,\n",
      "  \"remove_invalid_values\": false,\n",
      "  \"exponential_decay_length_penalty\": null,\n",
      "  \"suppress_tokens\": null,\n",
      "  \"begin_suppress_tokens\": null,\n",
      "  \"architectures\": [\n",
      "    \"Ovis2_5\"\n",
      "  ],\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"tokenizer_class\": null,\n",
      "  \"prefix\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"pad_token_id\": null,\n",
      "  \"eos_token_id\": null,\n",
      "  \"sep_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"task_specific_params\": null,\n",
      "  \"problem_type\": null,\n",
      "  \"_name_or_path\": \"AIDC-AI/Ovis2.5-2B\",\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"AIDC-AI/Ovis2.5-2B--configuration_ovis2_5.Ovis2_5_Config\",\n",
      "    \"AutoModelForCausalLM\": \"AIDC-AI/Ovis2.5-2B--modeling_ovis2_5.Ovis2_5\"\n",
      "  },\n",
      "  \"conversation_formatter_class\": \"Qwen3ConversationFormatter\",\n",
      "  \"vocab_size\": 151936,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"max_position_embeddings\": 40960,\n",
      "  \"model_type\": \"ovis2_5\",\n",
      "  \"use_cache\": true,\n",
      "  \"llm_config\": {\n",
      "    \"vocab_size\": 151936,\n",
      "    \"max_position_embeddings\": 40960,\n",
      "    \"hidden_size\": 2048,\n",
      "    \"intermediate_size\": 6144,\n",
      "    \"num_hidden_layers\": 28,\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"use_sliding_window\": false,\n",
      "    \"sliding_window\": null,\n",
      "    \"max_window_layers\": 28,\n",
      "    \"num_key_value_heads\": 8,\n",
      "    \"head_dim\": 128,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"rms_norm_eps\": 1e-06,\n",
      "    \"use_cache\": true,\n",
      "    \"rope_theta\": 1000000,\n",
      "    \"rope_scaling\": null,\n",
      "    \"attention_bias\": false,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"return_dict\": true,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_attentions\": false,\n",
      "    \"torchscript\": false,\n",
      "    \"torch_dtype\": \"bfloat16\",\n",
      "    \"use_bfloat16\": false,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"pruned_heads\": {},\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"is_decoder\": false,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"add_cross_attention\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"temperature\": 1.0,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_scores\": false,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"architectures\": [\n",
      "      \"Qwen3ForCausalLM\"\n",
      "    ],\n",
      "    \"finetuning_task\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"tokenizer_class\": null,\n",
      "    \"prefix\": null,\n",
      "    \"bos_token_id\": 151643,\n",
      "    \"pad_token_id\": null,\n",
      "    \"eos_token_id\": 151645,\n",
      "    \"sep_token_id\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"_name_or_path\": \"Qwen/Qwen3-1.7B\",\n",
      "    \"_attn_implementation_autoset\": true,\n",
      "    \"model_type\": \"qwen3\"\n",
      "  },\n",
      "  \"vit_config\": {\n",
      "    \"return_dict\": true,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_attentions\": false,\n",
      "    \"torchscript\": false,\n",
      "    \"torch_dtype\": \"bfloat16\",\n",
      "    \"use_bfloat16\": false,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"pruned_heads\": {},\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"is_decoder\": false,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"add_cross_attention\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"temperature\": 1.0,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_scores\": false,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"architectures\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"tokenizer_class\": null,\n",
      "    \"prefix\": null,\n",
      "    \"bos_token_id\": null,\n",
      "    \"pad_token_id\": null,\n",
      "    \"eos_token_id\": null,\n",
      "    \"sep_token_id\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"_name_or_path\": \"google/siglip2-so400m-patch16-512\",\n",
      "    \"_attn_implementation_autoset\": true,\n",
      "    \"model_type\": \"siglip2_navit\",\n",
      "    \"hidden_size\": 1152,\n",
      "    \"intermediate_size\": 4304,\n",
      "    \"num_hidden_layers\": 27,\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"num_channels\": 3,\n",
      "    \"num_patches\": -1,\n",
      "    \"patch_size\": 16,\n",
      "    \"image_size\": 512,\n",
      "    \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"layer_norm_eps\": 1e-06,\n",
      "    \"hidden_stride\": 2,\n",
      "    \"window_size\": 112,\n",
      "    \"fullatt_block_indexes\": null,\n",
      "    \"temporal_patch_size\": 1,\n",
      "    \"preserve_original_pe\": true,\n",
      "    \"use_rope\": true\n",
      "  },\n",
      "  \"visual_vocab_size\": 65536,\n",
      "  \"hidden_size\": 2048\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cfg = model.config.to_dict()  \n",
    "print(json.dumps(cfg, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dfbbb1-b63f-4d29-b376-e54e6cc6d35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ayush Env",
   "language": "python",
   "name": "ayush"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
